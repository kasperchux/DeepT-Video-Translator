{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# In this notebook: \n",
    "   * Choose three summarization models\n",
    "   * Calculate the most popular metrics\n",
    "   * Choose one from all models to use it in my project"
   ],
   "id": "640f536dae21b59b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Import all libraries and dependencies",
   "id": "3ce1ece912e05c1b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T15:10:23.647082Z",
     "start_time": "2024-06-15T15:10:18.727793Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install bert_score",
   "id": "cd4a8cfca875dfd0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert_score\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: torch>=1.0.0 in c:\\users\\user\\.conda\\envs\\coding\\lib\\site-packages (from bert_score) (2.3.0+cu118)\n",
      "Requirement already satisfied: pandas>=1.0.1 in c:\\users\\user\\.conda\\envs\\coding\\lib\\site-packages (from bert_score) (2.2.2)\n",
      "Requirement already satisfied: transformers>=3.0.0 in c:\\users\\user\\.conda\\envs\\coding\\lib\\site-packages (from bert_score) (4.41.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\.conda\\envs\\coding\\lib\\site-packages (from bert_score) (1.26.4)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\.conda\\envs\\coding\\lib\\site-packages (from bert_score) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in c:\\users\\user\\.conda\\envs\\coding\\lib\\site-packages (from bert_score) (4.66.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\.conda\\envs\\coding\\lib\\site-packages (from bert_score) (3.8.4)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\user\\.conda\\envs\\coding\\lib\\site-packages (from bert_score) (24.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\.conda\\envs\\coding\\lib\\site-packages (from pandas>=1.0.1->bert_score) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\.conda\\envs\\coding\\lib\\site-packages (from pandas>=1.0.1->bert_score) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\.conda\\envs\\coding\\lib\\site-packages (from pandas>=1.0.1->bert_score) (2024.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\.conda\\envs\\coding\\lib\\site-packages (from torch>=1.0.0->bert_score) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\user\\.conda\\envs\\coding\\lib\\site-packages (from torch>=1.0.0->bert_score) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\user\\.conda\\envs\\coding\\lib\\site-packages (from torch>=1.0.0->bert_score) (1.12.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\.conda\\envs\\coding\\lib\\site-packages (from torch>=1.0.0->bert_score) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\.conda\\envs\\coding\\lib\\site-packages (from torch>=1.0.0->bert_score) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\.conda\\envs\\coding\\lib\\site-packages (from torch>=1.0.0->bert_score) (2024.3.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\user\\.conda\\envs\\coding\\lib\\site-packages (from torch>=1.0.0->bert_score) (2021.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\.conda\\envs\\coding\\lib\\site-packages (from tqdm>=4.31.1->bert_score) (0.4.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in c:\\users\\user\\.conda\\envs\\coding\\lib\\site-packages (from transformers>=3.0.0->bert_score) (0.23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\.conda\\envs\\coding\\lib\\site-packages (from transformers>=3.0.0->bert_score) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\.conda\\envs\\coding\\lib\\site-packages (from transformers>=3.0.0->bert_score) (2024.4.28)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\user\\.conda\\envs\\coding\\lib\\site-packages (from transformers>=3.0.0->bert_score) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\user\\.conda\\envs\\coding\\lib\\site-packages (from transformers>=3.0.0->bert_score) (0.4.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\.conda\\envs\\coding\\lib\\site-packages (from matplotlib->bert_score) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\.conda\\envs\\coding\\lib\\site-packages (from matplotlib->bert_score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\.conda\\envs\\coding\\lib\\site-packages (from matplotlib->bert_score) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\.conda\\envs\\coding\\lib\\site-packages (from matplotlib->bert_score) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\user\\.conda\\envs\\coding\\lib\\site-packages (from matplotlib->bert_score) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\.conda\\envs\\coding\\lib\\site-packages (from matplotlib->bert_score) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\.conda\\envs\\coding\\lib\\site-packages (from requests->bert_score) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\.conda\\envs\\coding\\lib\\site-packages (from requests->bert_score) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\.conda\\envs\\coding\\lib\\site-packages (from requests->bert_score) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\.conda\\envs\\coding\\lib\\site-packages (from requests->bert_score) (2024.2.2)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\user\\.conda\\envs\\coding\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.0.0->bert_score) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\user\\.conda\\envs\\coding\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.0.0->bert_score) (2021.12.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\.conda\\envs\\coding\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\.conda\\envs\\coding\\lib\\site-packages (from jinja2->torch>=1.0.0->bert_score) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in c:\\users\\user\\.conda\\envs\\coding\\lib\\site-packages (from sympy->torch>=1.0.0->bert_score) (1.3.0)\n",
      "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "   ---------------------------------------- 0.0/61.1 kB ? eta -:--:--\n",
      "   ------ --------------------------------- 10.2/61.1 kB ? eta -:--:--\n",
      "   -------------------- ------------------- 30.7/61.1 kB 640.0 kB/s eta 0:00:01\n",
      "   -------------------------- ------------- 41.0/61.1 kB 279.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 61.1/61.1 kB 361.0 kB/s eta 0:00:00\n",
      "Installing collected packages: bert_score\n",
      "Successfully installed bert_score-0.3.13\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T15:44:19.797365Z",
     "start_time": "2024-06-16T15:44:11.652072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModel, BartForCausalLM, pipeline\n",
    "import numpy as np\n",
    "from rouge import Rouge\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from bert_score import score"
   ],
   "id": "998bf00f7b0bd6e1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\.conda\\envs\\coding\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Let's load all models",
   "id": "3fe45e761bf7b5e2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# There are..\n",
    "   * Ainiz\\Bart Base CNN\n",
    "   * Kasperchux\\BartBaseSummarization (It's my model)\n",
    "   * Falconsai/text-summarization"
   ],
   "id": "e686c07015681082"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T15:44:24.820169Z",
     "start_time": "2024-06-16T15:44:23.130777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer_1 = AutoTokenizer.from_pretrained(\"ainize/bart-base-cnn\")\n",
    "model_1 = BartForCausalLM.from_pretrained(\"ainize/bart-base-cnn\")"
   ],
   "id": "a29a00a4d7e35a31",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T15:44:25.899674Z",
     "start_time": "2024-06-16T15:44:24.863182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer_3 = AutoTokenizer.from_pretrained(\"Falconsai/text_summarization\")\n",
    "model_3 = AutoModelForSeq2SeqLM.from_pretrained(\"Falconsai/text_summarization\")"
   ],
   "id": "b9b2a56c0479211c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T15:44:31.208Z",
     "start_time": "2024-06-16T15:44:29.557761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer_2 = AutoTokenizer.from_pretrained(\"kasperchux/Bart-Base-Summarization\")\n",
    "model_2 = AutoModelForSeq2SeqLM.from_pretrained(\"kasperchux/Bart-Base-Summarization\")"
   ],
   "id": "d388fe0ac3379afc",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Essential function to summarize the text\n",
    " We will use it while testing model"
   ],
   "id": "8bf3841106e3e50d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This code taken from Bart-Base page on Hugging Face.",
   "id": "36325c70bda1ddc0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T16:02:01.230527Z",
     "start_time": "2024-06-16T16:02:01.225814Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def summarize_bart_base_func(model, tokenizer, input_text):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "\n",
    "    # Generate Summary Text Ids\n",
    "    summary_text_ids = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        bos_token_id=model.config.bos_token_id,\n",
    "        eos_token_id=model.config.eos_token_id,\n",
    "        length_penalty=2.0,\n",
    "        max_length=1000,\n",
    "        min_length=56,\n",
    "        num_beams=4,\n",
    "    )\n",
    "    \n",
    "    # Decoding Text\n",
    "    return tokenizer.decode(summary_text_ids[0], skip_special_tokens=True)"
   ],
   "id": "7c7afb3f982680c3",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This code taken from model_interface/Summarizer.py",
   "id": "182b545b23fdac2b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T15:44:35.891852Z",
     "start_time": "2024-06-16T15:44:35.888322Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def summarize_bart_base_kasperchuk_func(model, tokenizer, text: str) -> str:\n",
    "    input_ids = tokenizer.encode(text, return_tensors='pt') # Encode it\n",
    "    output = model.generate(input_ids)  # Get summarized text \n",
    "    output_text = tokenizer.decode(output[0], skip_special_tokens=True) # Decode it.\n",
    "    return output_text "
   ],
   "id": "9a74f7e8c3603876",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T15:48:33.853893Z",
     "start_time": "2024-06-16T15:48:33.849991Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def summarize_falcon_func(model, tokenizer, text) -> str:\n",
    "    summarizer = pipeline(\"summarization\", model=model, tokenizer=tokenizer)\n",
    "    summ = summarizer(text, max_length=800, min_length=0, do_sample=False)\n",
    "    return summ[0][\"summary_text\"]"
   ],
   "id": "eb62dcd9a86b418c",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Download dataset to calculate metrics\n",
    " it will be \"abisee/cnn_dailymail\""
   ],
   "id": "18d98a41aa5edd5c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T15:44:50.359486Z",
     "start_time": "2024-06-16T15:44:44.452185Z"
    }
   },
   "cell_type": "code",
   "source": "test_dataset = load_dataset(\"abisee/cnn_dailymail\", \"3.0.0\", split=\"test\")",
   "id": "2c6cf633462acef5",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T16:14:02.159733Z",
     "start_time": "2024-06-16T16:14:02.155392Z"
    }
   },
   "cell_type": "code",
   "source": "test_sample = test_dataset.select(range(50)) # Select 20 rows from dataset ",
   "id": "99d6df907266d384",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T15:44:50.375068Z",
     "start_time": "2024-06-16T15:44:50.366440Z"
    }
   },
   "cell_type": "code",
   "source": "test_sample[0]",
   "id": "2180895e639f4eb9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'article': '(CNN)The Palestinian Authority officially became the 123rd member of the International Criminal Court on Wednesday, a step that gives the court jurisdiction over alleged crimes in Palestinian territories. The formal accession was marked with a ceremony at The Hague, in the Netherlands, where the court is based. The Palestinians signed the ICC\\'s founding Rome Statute in January, when they also accepted its jurisdiction over alleged crimes committed \"in the occupied Palestinian territory, including East Jerusalem, since June 13, 2014.\" Later that month, the ICC opened a preliminary examination into the situation in Palestinian territories, paving the way for possible war crimes investigations against Israelis. As members of the court, Palestinians may be subject to counter-charges as well. Israel and the United States, neither of which is an ICC member, opposed the Palestinians\\' efforts to join the body. But Palestinian Foreign Minister Riad al-Malki, speaking at Wednesday\\'s ceremony, said it was a move toward greater justice. \"As Palestine formally becomes a State Party to the Rome Statute today, the world is also a step closer to ending a long era of impunity and injustice,\" he said, according to an ICC news release. \"Indeed, today brings us closer to our shared goals of justice and peace.\" Judge Kuniko Ozaki, a vice president of the ICC, said acceding to the treaty was just the first step for the Palestinians. \"As the Rome Statute today enters into force for the State of Palestine, Palestine acquires all the rights as well as responsibilities that come with being a State Party to the Statute. These are substantive commitments, which cannot be taken lightly,\" she said. Rights group Human Rights Watch welcomed the development. \"Governments seeking to penalize Palestine for joining the ICC should immediately end their pressure, and countries that support universal acceptance of the court\\'s treaty should speak out to welcome its membership,\" said Balkees Jarrah, international justice counsel for the group. \"What\\'s objectionable is the attempts to undermine international justice, not Palestine\\'s decision to join a treaty to which over 100 countries around the world are members.\" In January, when the preliminary ICC examination was opened, Israeli Prime Minister Benjamin Netanyahu described it as an outrage, saying the court was overstepping its boundaries. The United States also said it \"strongly\" disagreed with the court\\'s decision. \"As we have said repeatedly, we do not believe that Palestine is a state and therefore we do not believe that it is eligible to join the ICC,\" the State Department said in a statement. It urged the warring sides to resolve their differences through direct negotiations. \"We will continue to oppose actions against Israel at the ICC as counterproductive to the cause of peace,\" it said. But the ICC begs to differ with the definition of a state for its purposes and refers to the territories as \"Palestine.\" While a preliminary examination is not a formal investigation, it allows the court to review evidence and determine whether to investigate suspects on both sides. Prosecutor Fatou Bensouda said her office would \"conduct its analysis in full independence and impartiality.\" The war between Israel and Hamas militants in Gaza last summer left more than 2,000 people dead. The inquiry will include alleged war crimes committed since June. The International Criminal Court was set up in 2002 to prosecute genocide, crimes against humanity and war crimes. CNN\\'s Vasco Cotovio, Kareem Khadder and Faith Karimi contributed to this report.',\n",
       " 'highlights': 'Membership gives the ICC jurisdiction over alleged crimes committed in Palestinian territories since last June .\\nIsrael and the United States opposed the move, which could open the door to war crimes investigations against Israelis .',\n",
       " 'id': 'f001ec5c4704938247d27a44948eebb37ae98d01'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T16:14:04.666326Z",
     "start_time": "2024-06-16T16:14:04.661697Z"
    }
   },
   "cell_type": "code",
   "source": "test_sample.remove_columns([\"id\"])",
   "id": "f1c52a5baff4115b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['article', 'highlights'],\n",
       "    num_rows: 50\n",
       "})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T16:14:06.765391Z",
     "start_time": "2024-06-16T16:14:06.758770Z"
    }
   },
   "cell_type": "code",
   "source": "references = [ex[\"highlights\"] for ex in test_sample] # Get only summary",
   "id": "2ae122e873f8eeb",
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T16:14:08.031856Z",
     "start_time": "2024-06-16T16:14:08.027792Z"
    }
   },
   "cell_type": "code",
   "source": "references",
   "id": "2ba59eff954f938f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Membership gives the ICC jurisdiction over alleged crimes committed in Palestinian territories since last June .\\nIsrael and the United States opposed the move, which could open the door to war crimes investigations against Israelis .',\n",
       " 'Theia, a bully breed mix, was apparently hit by a car, whacked with a hammer and buried in a field .\\n\"She\\'s a true miracle dog and she deserves a good life,\" says Sara Mellado, who is looking for a home for Theia .',\n",
       " 'Mohammad Javad Zarif has spent more time with John Kerry than any other foreign minister .\\nHe once participated in a takeover of the Iranian Consulate in San Francisco .\\nThe Iranian foreign minister tweets in English .',\n",
       " '17 Americans were exposed to the Ebola virus while in Sierra Leone in March .\\nAnother person was diagnosed with the disease and taken to hospital in Maryland .\\nNational Institutes of Health says the patient is in fair condition after weeks of treatment .',\n",
       " 'Student is no longer on Duke University campus and will face disciplinary review .\\nSchool officials identified student during investigation and the person admitted to hanging the noose, Duke says .\\nThe noose, made of rope, was discovered on campus about 2 a.m.',\n",
       " 'College-bound basketball star asks girl with Down syndrome to high school prom .\\nPictures of the two during the \"prom-posal\" have gone viral .',\n",
       " \"Amnesty's annual death penalty report catalogs encouraging signs, but setbacks in numbers of those sentenced to death .\\nOrganization claims that governments around the world are using the threat of terrorism to advance executions .\\nThe number of executions worldwide has gone down by almost 22% compared with 2013, but death sentences up by 28% .\",\n",
       " \"Andrew Getty's death appears to be from natural causes, police say, citing coroner's early assessment .\\nIn a petition for a restraining order, Getty had written he had a serious medical condition.\\nPolice say this is not a criminal matter at this time .\",\n",
       " 'Once a super typhoon, Maysak is now a tropical storm with 70 mph winds .\\nIt could still cause flooding, landslides and other problems in the Philippines .',\n",
       " 'Bob Barker returned to host \"The Price Is Right\" on Wednesday .\\nBarker, 91, had retired as host in 2007 .',\n",
       " \"London's Metropolitan Police say the man was arrested at Luton airport after landing on a flight from Istanbul .\\nHe's been charged with terror offenses allegedly committed since the start of November .\",\n",
       " '\"Furious 7\" pays tribute to star Paul Walker, who died during filming .\\nVin Diesel: \"This movie is more than a movie\"\\n\"Furious 7\" opens Friday .',\n",
       " 'Museum: Anne Frank died earlier than previously believed .\\nResearchers re-examined archives and testimonies of survivors .\\nAnne and older sister Margot Frank are believed to have died in February 1945 .',\n",
       " 'LZ: Indiana law pushing back LGBT rights, and other states\\' anti-LGBT moves, bow to far right wing that GOP candidates need for 2016 .\\nCruz, Huckabee, Jindal, Carson, Walker are reviving culture wars, he says.  Equality for LGBT has not yet \"won\" in America .',\n",
       " 'Singing the national anthem is a risky proposition .\\nWhitney Houston nailed it; Roseanne Barr destroyed it .',\n",
       " 'While Republican Gov. Asa Hutchinson was weighing an Arkansas religious freedom bill, Walmart voiced its opposition .\\nWalmart and other high-profile businesses are showing their support for gay and lesbian rights .\\nTheir stance puts them in conflict with socially conservative Republicans, traditionally seen as allies .',\n",
       " 'Amnesty International releases its annual review of the death penalty worldwide; much of it makes for grim reading .\\nSalil Shetty: Countries that use executions to deal with problems are on the wrong side of history .',\n",
       " 'Marseille prosecutor says \"so far no videos were used in the crash investigation\" despite media reports .\\nJournalists at Bild and Paris Match are \"very confident\" the video clip is real, an editor says .\\nAndreas Lubitz had informed his Lufthansa training school of an episode of severe depression, airline says .',\n",
       " 'The Rev. Robert Schuller, 88, had been diagnosed with esophageal cancer in 2013 .\\nHis TV show, \"Hour of Power,\" was enormously popular in the 1970s and 1980s .',\n",
       " 'Former GOP representative compares President Obama to Andreas Lubitz .\\nBachmann said with possible Iran deal, Obama will fly \"entire nation into the rocks\"\\nReaction on social media? She was blasted by Facebook commenters .',\n",
       " 'Father: \"I know he went through what he went through\"\\nLouis Jordan was found on his sailboat, which was listing and in bad shape, rescuer says .\\nHe appears to be in good shape, physically and mentally .',\n",
       " 'Richard Klass: Iran framework agreement on nukes is strong, but opponents will cast doubts on this and try to obscure its facts .\\nHe says the deal would cut uranium stockpile, centrifuges, implement rigorous inspections; it should be judged on merits, not disinformation .',\n",
       " 'Americans paid more for some fruits and vegetables last year because of the drought .\\nTourists will now have to ask for a glass of water at a California restaurant .\\nPerhaps the only good thing is another \"great\" wine grape harvest last year .',\n",
       " \"The FBI cites social media messages sent by Keonna Thomas, 30 .\\nShe's accused of trying to travel overseas to join ISIS .\\nThomas is one of three women facing federal terror charges this week .\",\n",
       " 'Iranian sports official: The ban will be lifted for some events in the coming year .\\nBut he says \"families are not interested in attending\" some sports matches .',\n",
       " 'Going online has become the path of least resistance if you want to make yourself heard .\\nBut where there is the restrictive rule of law, journalists are vulnerable to the anger of officialdom .\\nFrom China to Malaysia, journalists and bloggers have been jailed -- even killed .',\n",
       " 'The singer had been off the scene for a while .\\nShe says she was bedridden for months .\\nLavigne was sometimes too weak to shower .',\n",
       " \"Here are six of CNN's best videos of the week .\\nClips include a look at Mike Tyson's abandoned mansion .\",\n",
       " 'Netanyahu says third option is \"standing firm\" to get a better deal .\\nPolitical sparring continues in U.S. over the deal with Iran .',\n",
       " \"Indiana town's Memories Pizza is shut down after online threat .\\nIts owners say they'd refuse to cater a same-sex couple's wedding .\",\n",
       " \"Authorities in the Indian city of Malegaon have asked residents to take a 'mugshot' of their cattle .\\nCows are revered by the majority Hindu population, and many parts of the country have laws banning the slaughter of cattle .\\nOfficials in Malegaon believe this is the best way to solve cow slaughter cases and enforce the law .\",\n",
       " 'A South Carolina man says he spent 66 days alone at sea before being rescued .\\nOther sole survivor stories include a Japanese man washed away by a tsunami .\\nAn El Salvador man says he drifted from Mexico to Marshall Islands over a year .',\n",
       " 'The Large Hadron Collider (LHC) begins again after a two-year shutdown .\\nThe restart was delayed in March .',\n",
       " 'FBI agents and a suspected serial robber exchange gunfire in an FBI stakeout .\\nTwo FBI agents are injured and the suspect is shot during the gunfight .',\n",
       " 'The total eclipse will only last 4 minutes and 43 seconds .\\nPeople west of the Mississippi River will have the best view .\\nParts of South America, India, China and Russia also will see the eclipse .',\n",
       " 'Terrorist group Al-Shabaab has attacked a Kenyan college, killing and taking hostages .\\nIt is a clear indicator the security situation in East Africa is deteriorating, says Stefan Wolff .\\nMore than military action aloe is needed to combat terrorism in the region, he says .',\n",
       " 'Easter is a key event in the Christian faith, but where did the Easter Bunny come from?\\nWhy is the date different every year, and what does it have to do with the moon?',\n",
       " 'In response to lawsuit, NCAA says it doesn\\'t control quality of education for student-athletes .\\nBut its website emphasizes importance of education, \"opportunities to learn\"\\nLawsuit claims students didn\\'t get an education because of academic fraud at UNC .',\n",
       " \"Judge won't allow teen leave hospital before her last chemotherapy treatment .\\nAttorneys for the teen are deciding whether to appeal .\\nCassandra C. is now in remission and is no longer opposed to the chemotherapy treatments .\",\n",
       " 'The song rules the chart for 13th week .\\nIt passes Robin Thicke\\'s \"Blurred Lines\"\\nSong three weeks from potentially tying \"One Sweet Day\" for record .',\n",
       " 'High temperatures are recorded on the northern tip of the Antarctica Peninsula .\\nThe World Meteorological Organization will make the final determination .',\n",
       " 'A Native American from a tribe not recognized by the feds wins the return of his eagle feathers .\\nAn IRS accountant is fired for insisting on carrying a symbolic Sikh knife to work .\\nA group of Chicago pastors takes on City Hall over its permits for new churches and loses .',\n",
       " \"Robert Lewis Burns Jr. was part of Lynyrd Skynyrd's original lineup .\\nHis car hit a mailbox and a tree just before midnight .\",\n",
       " \"Kim Ki-Jong is charged with attempted murder and assaulting a foreign envoy .\\nHe's accused of stabbing U.S. Ambassador Mark Lippert in the face and arm .\\nPolice said Kim opposed the joint U.S.-South Korean military drills .\",\n",
       " 'Hong Kong banker alleged murder case adjourned until May .\\nThe 29-year-old Rurik Jutting is accused of killing two Indonesian domestic workers .',\n",
       " 'Thai Airways subsidiary Thai Smile features Cartoon Network paint job on A320 jet .\\nOverhead bins, head rests and air sick bags feature characters from Cartoon Network .',\n",
       " 'Manning is serving a 35-year sentence for leaking thousands of classified documents .\\nShe says she will be using a voice phone to dictate her tweets .',\n",
       " 'Frida Ghitis: President Barack Obama is right to want a deal, but this one gives Iran too much .\\nShe says the framework agreement starts lifting Iran sanctions much too soon .',\n",
       " 'The final film featuring the late Paul Walker, \"Furious 7\" is opening around the globe this weekend .\\nIt\\'s worldwide debut may approach or cross $300 million by the end of Easter Sunday .',\n",
       " 'Deion Sanders calls out son for \"hood doughnuts\" comments .\\n\"You\\'re a Huxtable with a million $ trust fund. Stop the hood stuff!\"']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# And now, let's write function 'calculate_metrics'",
   "id": "a9751aad2d13b9a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T15:59:45.494584Z",
     "start_time": "2024-06-16T15:59:45.488692Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_metrics(model, tokenizer, func_summarize) -> list:\n",
    "    rouge_list = []\n",
    "    bleu_list = []\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    f1_score_list = []\n",
    "    \n",
    "    for index, example in enumerate(test_sample):\n",
    "        # Take example from sample\n",
    "        source = example[\"article\"]\n",
    "        summary = func_summarize(model, tokenizer, source)\n",
    "        \n",
    "        # Calculate BLEU-metric\n",
    "        tokenized_summary = nltk.word_tokenize(summary, language=\"english\")\n",
    "        tokenized_reference = nltk.word_tokenize(references[index], language=\"english\")\n",
    "        cur_bleu = sentence_bleu([tokenized_reference], tokenized_summary)\n",
    "        bleu_list.append(cur_bleu)\n",
    "        \n",
    "        # Calculate Bert-Score\n",
    "        precision, recall, f1 = score(\n",
    "        [summary], [references[index]], lang='en', verbose=False)\n",
    "        precision = float(precision)\n",
    "        recall = float(recall)\n",
    "        f1 = float(f1)\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_score_list.append(f1)\n",
    "\n",
    "        # Return all metrics\n",
    "    return [bleu_list, precision_list, recall_list, f1_score_list]\n",
    "            "
   ],
   "id": "357497460f2794f8",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Metrics\n",
    "\n",
    "### 1. ROUGE (Recall-Oriented Understudy for Gisting Evaluation)\n",
    "\n",
    "**Formula:**\n",
    "\n",
    "$$\n",
    "\\text{ROUGE-N} = \\frac{\\sum_{} \\text{Count of N-grams in S} \\cap \\text{Count of N-grams in Candidate Summary}}{\\text{Count of N-grams in Summary}}\n",
    "$$\n",
    "\n",
    "**About it:**\n",
    "\n",
    "* ROUGE-N measures the concordance of N-grams (sequences of N words) between the abstract and the source text.\n",
    "* The higher the ROUGE-N value, the more N-grams match, indicating a better quality abstract.\n",
    "\n",
    "### 2. BLEU (Bilingual Evaluation Understudy)\n",
    "\n",
    "**Formula:**\n",
    "\n",
    "$$\n",
    "\\text{BLEU} = \\text{BP} \\times \\exp\\left(\\sum_{n=1}^N w_n \\log p_n \\right)\n",
    "$$\n",
    "\n",
    "**Where:**\n",
    "\n",
    "* BP - penalty for too short abstracts.\n",
    "* $p_n$ - accuracy of N-grams.\n",
    "* $w_n$ - weights for different N-grams.\n",
    "\n",
    "**About it:**\n",
    "\n",
    "* BLEU measures the accuracy and smoothness of the abstract compared to the source text.\n",
    "* The higher the BLEU value, the more accurate and smooth the abstract.\n",
    "\n",
    "### 3. BERTScore\n",
    "\n",
    "**Formula:**\n",
    "\n",
    "$$\n",
    "\\text{BERTScore} = \\frac{S(c,r) + S(r,c)}{2}\n",
    "$$\n",
    "\n",
    "**Where:**\n",
    "\n",
    "* $S(c,r)$ - evaluation of the similarity of the abstract ($c$) with the source text ($r$) according to the BERT model.\n",
    "* $S(r,c)$ - evaluation of the similarity of the source text ($r$) with the abstract ($c$) according to the BERT model.\n",
    "\n",
    "**About it:**\n",
    "\n",
    "* BERTScore uses the BERT model to evaluate the semantic similarity between the abstract and the source text.\n",
    "* The higher the BERTScore value, the greater the semantic similarity, indicating a better quality abstract."
   ],
   "id": "d62cc348e06d2f20"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Let's calculate all metrics",
   "id": "732da4c568e8d342"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T16:04:45.177349Z",
     "start_time": "2024-06-16T16:02:07.721237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metrics_bart_base = calculate_metrics(model_1, tokenizer_1, summarize_bart_base_func)\n",
    "print(\"Bart-Base's already calculated!\")"
   ],
   "id": "eb96d7a7f7c18149",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bart-Base's already calculated!\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T16:14:52.100855Z",
     "start_time": "2024-06-16T16:14:18.481835Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metrics_kasperchux_bart_base = calculate_metrics(model_2, tokenizer_2, summarize_bart_base_kasperchuk_func)\n",
    "print(\"Kasperchux/Bart-Base's already calculated!\")"
   ],
   "id": "19f690467a3b7905",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\.conda\\envs\\coding\\Lib\\site-packages\\transformers\\generation\\utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\.conda\\envs\\coding\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\User\\.conda\\envs\\coding\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\User\\.conda\\envs\\coding\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[77], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m metrics_kasperchux_bart_base \u001B[38;5;241m=\u001B[39m \u001B[43mcalculate_metrics\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtokenizer_2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msummarize_bart_base_kasperchuk_func\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mKasperchux/Bart-Base\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ms already calculated!\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[37], line 11\u001B[0m, in \u001B[0;36mcalculate_metrics\u001B[1;34m(model, tokenizer, func_summarize)\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m index, example \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(test_sample):\n\u001B[0;32m      9\u001B[0m     \u001B[38;5;66;03m# Take example from sample\u001B[39;00m\n\u001B[0;32m     10\u001B[0m     source \u001B[38;5;241m=\u001B[39m example[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marticle\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m---> 11\u001B[0m     summary \u001B[38;5;241m=\u001B[39m \u001B[43mfunc_summarize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msource\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     13\u001B[0m     \u001B[38;5;66;03m# Calculate BLEU-metric\u001B[39;00m\n\u001B[0;32m     14\u001B[0m     tokenized_summary \u001B[38;5;241m=\u001B[39m nltk\u001B[38;5;241m.\u001B[39mword_tokenize(summary, language\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124menglish\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[6], line 3\u001B[0m, in \u001B[0;36msummarize_bart_base_kasperchuk_func\u001B[1;34m(model, tokenizer, text)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msummarize_bart_base_kasperchuk_func\u001B[39m(model, tokenizer, text: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mstr\u001B[39m:\n\u001B[0;32m      2\u001B[0m     input_ids \u001B[38;5;241m=\u001B[39m tokenizer\u001B[38;5;241m.\u001B[39mencode(text, return_tensors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;66;03m# Encode it\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Get summarized text \u001B[39;00m\n\u001B[0;32m      4\u001B[0m     output_text \u001B[38;5;241m=\u001B[39m tokenizer\u001B[38;5;241m.\u001B[39mdecode(output[\u001B[38;5;241m0\u001B[39m], skip_special_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;66;03m# Decode it.\u001B[39;00m\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output_text\n",
      "File \u001B[1;32m~\\.conda\\envs\\coding\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[1;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\coding\\Lib\\site-packages\\transformers\\generation\\utils.py:1597\u001B[0m, in \u001B[0;36mGenerationMixin.generate\u001B[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001B[0m\n\u001B[0;32m   1591\u001B[0m     model_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mattention_mask\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_prepare_attention_mask_for_generation(\n\u001B[0;32m   1592\u001B[0m         inputs_tensor, generation_config\u001B[38;5;241m.\u001B[39mpad_token_id, generation_config\u001B[38;5;241m.\u001B[39meos_token_id\n\u001B[0;32m   1593\u001B[0m     )\n\u001B[0;32m   1595\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mis_encoder_decoder \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoder_outputs\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m model_kwargs:\n\u001B[0;32m   1596\u001B[0m     \u001B[38;5;66;03m# if model is encoder decoder encoder_outputs are created and added to `model_kwargs`\u001B[39;00m\n\u001B[1;32m-> 1597\u001B[0m     model_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_prepare_encoder_decoder_kwargs_for_generation\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1598\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs_tensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_input_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgeneration_config\u001B[49m\n\u001B[0;32m   1599\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1601\u001B[0m \u001B[38;5;66;03m# 5. Prepare `input_ids` which will be used for auto-regressive generation\u001B[39;00m\n\u001B[0;32m   1602\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mis_encoder_decoder:\n",
      "File \u001B[1;32m~\\.conda\\envs\\coding\\Lib\\site-packages\\transformers\\generation\\utils.py:523\u001B[0m, in \u001B[0;36mGenerationMixin._prepare_encoder_decoder_kwargs_for_generation\u001B[1;34m(self, inputs_tensor, model_kwargs, model_input_name, generation_config)\u001B[0m\n\u001B[0;32m    521\u001B[0m encoder_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreturn_dict\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    522\u001B[0m encoder_kwargs[model_input_name] \u001B[38;5;241m=\u001B[39m inputs_tensor\n\u001B[1;32m--> 523\u001B[0m model_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoder_outputs\u001B[39m\u001B[38;5;124m\"\u001B[39m]: ModelOutput \u001B[38;5;241m=\u001B[39m \u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mencoder_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    525\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model_kwargs\n",
      "File \u001B[1;32m~\\.conda\\envs\\coding\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\coding\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\coding\\Lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1163\u001B[0m, in \u001B[0;36mBartEncoder.forward\u001B[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m   1160\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m inputs_embeds \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1161\u001B[0m     inputs_embeds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membed_tokens(input_ids)\n\u001B[1;32m-> 1163\u001B[0m embed_pos \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membed_positions\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1164\u001B[0m embed_pos \u001B[38;5;241m=\u001B[39m embed_pos\u001B[38;5;241m.\u001B[39mto(inputs_embeds\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m   1166\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m inputs_embeds \u001B[38;5;241m+\u001B[39m embed_pos\n",
      "File \u001B[1;32m~\\.conda\\envs\\coding\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\coding\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\coding\\Lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:129\u001B[0m, in \u001B[0;36mBartLearnedPositionalEmbedding.forward\u001B[1;34m(self, input_ids, past_key_values_length)\u001B[0m\n\u001B[0;32m    124\u001B[0m bsz, seq_len \u001B[38;5;241m=\u001B[39m input_ids\u001B[38;5;241m.\u001B[39mshape[:\u001B[38;5;241m2\u001B[39m]\n\u001B[0;32m    125\u001B[0m positions \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39marange(\n\u001B[0;32m    126\u001B[0m     past_key_values_length, past_key_values_length \u001B[38;5;241m+\u001B[39m seq_len, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mlong, device\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight\u001B[38;5;241m.\u001B[39mdevice\n\u001B[0;32m    127\u001B[0m )\u001B[38;5;241m.\u001B[39mexpand(bsz, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m--> 129\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpositions\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moffset\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\coding\\Lib\\site-packages\\torch\\nn\\modules\\sparse.py:163\u001B[0m, in \u001B[0;36mEmbedding.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    162\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 163\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membedding\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    164\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_norm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    165\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnorm_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscale_grad_by_freq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msparse\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\coding\\Lib\\site-packages\\torch\\nn\\functional.py:2264\u001B[0m, in \u001B[0;36membedding\u001B[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001B[0m\n\u001B[0;32m   2258\u001B[0m     \u001B[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001B[39;00m\n\u001B[0;32m   2259\u001B[0m     \u001B[38;5;66;03m# XXX: equivalent to\u001B[39;00m\n\u001B[0;32m   2260\u001B[0m     \u001B[38;5;66;03m# with torch.no_grad():\u001B[39;00m\n\u001B[0;32m   2261\u001B[0m     \u001B[38;5;66;03m#   torch.embedding_renorm_\u001B[39;00m\n\u001B[0;32m   2262\u001B[0m     \u001B[38;5;66;03m# remove once script supports set_grad_enabled\u001B[39;00m\n\u001B[0;32m   2263\u001B[0m     _no_grad_embedding_renorm_(weight, \u001B[38;5;28minput\u001B[39m, max_norm, norm_type)\n\u001B[1;32m-> 2264\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membedding\u001B[49m\u001B[43m(\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadding_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscale_grad_by_freq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msparse\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mIndexError\u001B[0m: index out of range in self"
     ]
    }
   ],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T16:05:35.317683Z",
     "start_time": "2024-06-16T16:05:16.734216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metrics_falconai_ts = calculate_metrics(model_3, tokenizer_3, summarize_falcon_func)\n",
    "print(\"FalconAI's metrics already calculated\")"
   ],
   "id": "999348f56f08aeeb",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 800, but your input_length is only 789. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=394)\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Your max_length is set to 800, but your input_length is only 581. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=290)\n",
      "C:\\Users\\User\\.conda\\envs\\coding\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Your max_length is set to 800, but your input_length is only 269. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=134)\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Your max_length is set to 800, but your input_length is only 490. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=245)\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FalconAI's metrics already calculated\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T16:10:23.930475Z",
     "start_time": "2024-06-16T16:10:23.926604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_metrics_for_presentation(metrics):\n",
    "    bleu = metrics[0]\n",
    "    precision = metrics[1]\n",
    "    recall = metrics[2]\n",
    "    f1 = metrics[3]\n",
    "    \n",
    "    avg_precision = np.mean(precision)\n",
    "    avg_recall = np.mean(recall)\n",
    "    avg_f1 = np.mean(f1)\n",
    "    avg_bleu = np.mean(bleu)\n",
    "    return avg_bleu, avg_precision, avg_recall, avg_f1"
   ],
   "id": "f4806ced567b39c2",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T15:57:40.187421Z",
     "start_time": "2024-06-16T15:57:40.184161Z"
    }
   },
   "cell_type": "code",
   "source": "import pandas as pd",
   "id": "9cb3b1473fc201",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T16:12:15.872415Z",
     "start_time": "2024-06-16T16:12:15.869154Z"
    }
   },
   "cell_type": "code",
   "source": "import seaborn as sns",
   "id": "dab39c2f40fba062",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T16:10:35.192502Z",
     "start_time": "2024-06-16T16:10:35.189490Z"
    }
   },
   "cell_type": "code",
   "source": "bart_base_bleu, bart_base_precision, bart_base_recall, bart_base_f1_score = preprocess_metrics_for_presentation(metrics_bart_base)",
   "id": "ef26b7c6f0f45381",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T16:10:27.679974Z",
     "start_time": "2024-06-16T16:10:27.676590Z"
    }
   },
   "cell_type": "code",
   "source": "kbart_base_bleu, kbart_base_precision, kbart_base_recall, kbart_base_f1_score = preprocess_metrics_for_presentation(metrics_kasperchux_bart_base) ",
   "id": "5bf0d7270271f4dd",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T16:11:11.316619Z",
     "start_time": "2024-06-16T16:11:11.313086Z"
    }
   },
   "cell_type": "code",
   "source": "falcon_base_bleu, falcon_base_precision, falcon_base_recall, falcon_base_f1_score = preprocess_metrics_for_presentation(metrics_falconai_ts)",
   "id": "326dee2679da39c8",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T16:11:15.074809Z",
     "start_time": "2024-06-16T16:11:15.071153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.DataFrame(\n",
    "    {\"Model\": [\"Bart-Base\", \"Kasperchux\", \"FalconAI\"],\n",
    "     \"BLEU-Score\": [bart_base_bleu, kbart_base_bleu, falcon_base_bleu],\n",
    "     \"Precision\": [bart_base_precision, kbart_base_precision, falcon_base_precision],\n",
    "     \"Recall\": [bart_base_recall, kbart_base_recall, falcon_base_recall],\n",
    "     \"F1-Score\": [bart_base_f1_score, kbart_base_f1_score, falcon_base_f1_score],\n",
    "     }\n",
    ")"
   ],
   "id": "4e72ae41b728bbb8",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T17:03:42.143437Z",
     "start_time": "2024-06-16T17:03:42.013836Z"
    }
   },
   "cell_type": "code",
   "source": "sns.barplot(x=\"Model\", y=\"BLEU-Score\", data=df)",
   "id": "71f93cab48e913f8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Model', ylabel='BLEU-Score'>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T16:13:22.322353Z",
     "start_time": "2024-06-16T16:13:22.201597Z"
    }
   },
   "cell_type": "code",
   "source": "sns.barplot(x=\"Model\", y=\"F1-Score\", data=df)",
   "id": "23d3cd3513122709",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Model', ylabel='F1-Score'>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Let's come to conclusion..\n",
    "As we can see, FalconAI's model show's the best, it has the biggest BLEU and F1-Score. So i will use it in this project as summarizer.\n",
    "Bart-Base model also shows good result, but not so good as FalconAI. The third 'Kasperchux\\bart-base-summarization, my model shows\n",
    "the worth results in BLEU-metric. But it takes second place in F1-score. Bad results are in cause of very little num of training epochs (it's 1), and lack of computing units' "
   ],
   "id": "bb302df155fda1d0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
