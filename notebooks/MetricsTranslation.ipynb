{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook: \n",
    "  - Choose 2 models for translation\n",
    "  - Calculating their metrics\n",
    "  - Choose the best model to use it in my project"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Importing libraries"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T10:48:44.909820Z",
     "start_time": "2024-06-15T10:48:44.906985Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "from rouge import Rouge\n",
    "from datasets import load_dataset\n",
    "from nltk.tokenize import word_tokenize"
   ],
   "outputs": [],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T11:27:18.896923Z",
     "start_time": "2024-06-15T11:27:18.893178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.translate import meteor_score"
   ],
   "outputs": [],
   "execution_count": 122
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Save model names in variables"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T11:02:07.653520Z",
     "start_time": "2024-06-15T11:02:07.650201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_1_name = \"Helsinki-NLP/opus-mt-en-ru\" \n",
    "model_2_name = \"Gopal1853/marian-finetuned-kde4-en-to-ru\""
   ],
   "outputs": [],
   "execution_count": 104
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load my GPU"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T10:48:52.465405Z",
     "start_time": "2024-06-15T10:48:52.463025Z"
    }
   },
   "cell_type": "code",
   "source": "device = torch.device(\"cuda\")",
   "outputs": [],
   "execution_count": 94
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T10:48:54.089973Z",
     "start_time": "2024-06-15T10:48:54.086627Z"
    }
   },
   "cell_type": "code",
   "source": "device",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 95
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load all the models"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T11:04:30.495393Z",
     "start_time": "2024-06-15T11:02:11.010923Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer_1 = MarianTokenizer.from_pretrained(model_1_name)\n",
    "model_1 = MarianMTModel.from_pretrained(model_1_name).to(device)\n",
    "\n",
    "tokenizer_2 = AutoTokenizer.from_pretrained(model_2_name)\n",
    "model_2 = AutoModelForSeq2SeqLM.from_pretrained(model_2_name).to(device)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\.conda\\envs\\coding\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\.cache\\huggingface\\hub\\models--Gopal1853--marian-finetuned-kde4-en-to-ru. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "execution_count": 105
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T09:24:50.265601Z",
     "start_time": "2024-06-15T09:24:38.290660Z"
    }
   },
   "cell_type": "code",
   "source": "test_data = load_dataset(\"Helsinki-NLP/opus-100\", \"en-ru\", split=\"test\")",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T09:26:01.581232Z",
     "start_time": "2024-06-15T09:26:01.577466Z"
    }
   },
   "cell_type": "code",
   "source": "test_data",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['translation'],\n",
       "    num_rows: 2000\n",
       "})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T11:17:01.446279Z",
     "start_time": "2024-06-15T11:17:01.442118Z"
    }
   },
   "cell_type": "code",
   "source": "test_sample = test_data.select(range(100)) # Let's take first 10 lines",
   "outputs": [],
   "execution_count": 118
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T11:17:23.143078Z",
     "start_time": "2024-06-15T11:17:23.139655Z"
    }
   },
   "cell_type": "code",
   "source": "references = [ex[\"translation\"][\"ru\"] for ex in test_sample]",
   "outputs": [],
   "execution_count": 119
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Base function to check model prediction"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T11:36:39.644640Z",
     "start_time": "2024-06-15T11:36:09.853424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 130
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T10:27:27.055395Z",
     "start_time": "2024-06-15T10:27:27.051193Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def translate_text(model, tokenizer, text):\n",
    "    inputs = tokenizer.prepare_seq2seq_batch([text], truncation=True, padding=\"longest\", return_tensors=\"pt\").to(device)\n",
    "    translated_ids = model.generate(inputs.input_ids)\n",
    "    translated_text = tokenizer.decode(translated_ids[0], skip_special_tokens=True)\n",
    "    return translated_text"
   ],
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# BLEU Formula\n",
    "\n",
    " $$BLEU = BP \\cdot e^{\\sum{w_n \\cdot \\log(p_n)}}$$"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# ROUGE Formula\n",
    "\n",
    "$$ROUGE-N = \\frac{{\\text{{Count of matching n-grams}}}}{{\\text{{Count of n-grams in the reference summary}}}}$$"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# METEOR-metric's formula\n",
    "\n",
    "$$\\text{METEOR} = \\frac{{\\text{Precision} \\times \\text{Recall}}}{{(1 - \\alpha) \\times \\text{Precision} + \\alpha \\times \\text{Recall}}} \\times (1 - \\beta \\times \\text{Fragmentation})$$"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T11:36:43.032995Z",
     "start_time": "2024-06-15T11:36:43.027940Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_metrics(model, tokenizer):\n",
    "    BLEUFirst = []\n",
    "    RougeF1First = []\n",
    "    MeteorScore = []\n",
    "    rouge = Rouge()\n",
    "    \n",
    "    for i, ex in enumerate(test_sample):\n",
    "        source = ex[\"translation\"][\"en\"]\n",
    "        translated = translate_text(model, tokenizer, source)\n",
    "        prediction_tokens = word_tokenize(translated)\n",
    "        reference_tokens = word_tokenize(references[i])\n",
    "        bleu_cur = nltk.translate.bleu_score.sentence_bleu([reference_tokens], prediction_tokens)\n",
    "        BLEUFirst.append(bleu_cur)\n",
    "        rouge_cur = rouge.get_scores(references[i], translated)\n",
    "        rouge_l_score = rouge_cur[0]['rouge-l']['f']\n",
    "        RougeF1First.append(rouge_l_score)\n",
    "        meteor = meteor_score.meteor_score([reference_tokens], prediction_tokens)\n",
    "        MeteorScore.append(meteor)\n",
    "        \n",
    "    return BLEUFirst, RougeF1First, MeteorScore"
   ],
   "outputs": [],
   "execution_count": 131
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Let's look at metrics, and make a decision"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T11:36:53.814615Z",
     "start_time": "2024-06-15T11:36:44.747289Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bleu_1, rouge_1, meteor_1 = get_metrics(model_1, tokenizer_1)\n",
    "bleu_2, rouge_2, meteor_2 = get_metrics(model_2, tokenizer_2)"
   ],
   "outputs": [],
   "execution_count": 132
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T11:05:48.619026Z",
     "start_time": "2024-06-15T11:05:48.615909Z"
    }
   },
   "cell_type": "code",
   "source": "print(bleu_1)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.1640469867513693e-231, 8.129855005981316e-155, 4.101791032784236e-78, 0.3934995962231127, 0.1531682455208201, 4.188639545551841e-78, 0, 1.2882297539194154e-231, 0.43989172475842214, 1.2882297539194154e-231]\n"
     ]
    }
   ],
   "execution_count": 108
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T11:36:56.776978Z",
     "start_time": "2024-06-15T11:36:56.771799Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"{model_1_name}'s results: \")\n",
    "print(f\"Average BLEU: {np.mean(bleu_1):.4f}\")\n",
    "print(f\"Average Rouge F1: {np.mean(rouge_1):.4f}\")\n",
    "print(f\"Average Meteor: {np.mean(meteor_1):.4f}\")\n",
    "print(\"-----------------------------------------\")\n",
    "print(f\"{model_2_name}'s results: \")\n",
    "print(f\"Agerage BLEU: {np.mean(bleu_2)}\")\n",
    "print(f\"Average Rouge F1: {np.mean(rouge_2)}\")\n",
    "print(f\"Average Meteor: {np.mean(meteor_2)}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helsinki-NLP/opus-mt-en-ru's results: \n",
      "Average BLEU: 0.0987\n",
      "Average Rouge F1: 0.2938\n",
      "Average Meteor: 0.3821\n",
      "-----------------------------------------\n",
      "Gopal1853/marian-finetuned-kde4-en-to-ru's results: \n",
      "Agerage BLEU: 0.09786781163050493\n",
      "Average Rouge F1: 0.2937923569154086\n",
      "Average Meteor: 0.3721905498150912\n"
     ]
    }
   ],
   "execution_count": 133
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# In conclusion: as we can see, in terms of metrics these models are approximately equal, we can take both. But I preferred to take \"Helsinki-nlp/opus-mt-en-ru\""
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
